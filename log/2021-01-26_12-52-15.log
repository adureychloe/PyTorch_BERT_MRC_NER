2021-01-26 13:00:12 - configuration_utils.py[line:281] - INFO: loading configuration file ./pretrained_model/chinese_roberta_wwm_ext\config.json
2021-01-26 13:00:12 - configuration_utils.py[line:319] - INFO: Model config BertConfig {
  "_num_labels": 2,
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bad_words_ids": null,
  "bos_token_id": 0,
  "decoder_start_token_id": null,
  "directionality": "bidi",
  "do_sample": false,
  "early_stopping": false,
  "eos_token_id": 2,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "is_encoder_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "min_length": 0,
  "model_type": "bert",
  "no_repeat_ngram_size": 0,
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 1,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "prefix": null,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "task_specific_params": null,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 21128
}

2021-01-26 13:00:13 - modeling_utils.py[line:505] - INFO: loading weights file ./pretrained_model/chinese_roberta_wwm_ext\pytorch_model.bin
2021-01-26 13:00:51 - train.py[line:106] - INFO: epoch 0, step 50, loss 66.7159, start_f1 0.0205, end_f1 0.0471
2021-01-26 13:01:22 - train.py[line:106] - INFO: epoch 0, step 100, loss 52.6775, start_f1 0.0044, end_f1 0.0109
2021-01-26 13:01:54 - train.py[line:106] - INFO: epoch 0, step 150, loss 34.9200, start_f1 0.0000, end_f1 0.0190
2021-01-26 13:02:25 - train.py[line:106] - INFO: epoch 0, step 200, loss 16.3459, start_f1 0.0000, end_f1 0.0000
2021-01-26 13:02:56 - train.py[line:106] - INFO: epoch 0, step 250, loss 7.7657, start_f1 0.6415, end_f1 0.6481
2021-01-26 13:03:28 - train.py[line:106] - INFO: epoch 0, step 300, loss 5.0506, start_f1 0.6863, end_f1 0.6863
2021-01-26 13:03:59 - train.py[line:106] - INFO: epoch 0, step 350, loss 3.2156, start_f1 0.7586, end_f1 0.7500
2021-01-26 13:04:31 - train.py[line:106] - INFO: epoch 0, step 400, loss 3.3303, start_f1 0.7174, end_f1 0.7174
2021-01-26 13:05:02 - train.py[line:106] - INFO: epoch 0, step 450, loss 3.6614, start_f1 0.5882, end_f1 0.5783
2021-01-26 13:05:34 - train.py[line:106] - INFO: epoch 0, step 500, loss 4.0609, start_f1 0.6355, end_f1 0.6275
2021-01-26 13:06:05 - train.py[line:106] - INFO: epoch 0, step 550, loss 3.6067, start_f1 0.5946, end_f1 0.5818
2021-01-26 13:06:37 - train.py[line:106] - INFO: epoch 0, step 600, loss 3.9883, start_f1 0.5185, end_f1 0.5155
2021-01-26 13:07:08 - train.py[line:106] - INFO: epoch 0, step 650, loss 2.6919, start_f1 0.7679, end_f1 0.6727
2021-01-26 13:07:39 - train.py[line:106] - INFO: epoch 0, step 700, loss 1.9073, start_f1 0.7677, end_f1 0.7961
2021-01-26 13:08:11 - train.py[line:106] - INFO: epoch 0, step 750, loss 1.7816, start_f1 0.8431, end_f1 0.8598
2021-01-26 13:08:42 - train.py[line:106] - INFO: epoch 0, step 800, loss 2.0747, start_f1 0.8462, end_f1 0.8491
2021-01-26 13:09:14 - train.py[line:106] - INFO: epoch 0, step 850, loss 1.0906, start_f1 0.9057, end_f1 0.9159
2021-01-26 13:09:45 - train.py[line:106] - INFO: epoch 0, step 900, loss 1.3044, start_f1 0.8846, end_f1 0.9412
2021-01-26 13:10:16 - train.py[line:106] - INFO: epoch 0, step 950, loss 1.0104, start_f1 0.9138, end_f1 0.9153
2021-01-26 13:10:48 - train.py[line:106] - INFO: epoch 0, step 1000, loss 1.1183, start_f1 0.9038, end_f1 0.9174
2021-01-26 13:11:19 - train.py[line:106] - INFO: epoch 0, step 1050, loss 1.4770, start_f1 0.9027, end_f1 0.9091
2021-01-26 13:11:51 - train.py[line:106] - INFO: epoch 0, step 1100, loss 1.1064, start_f1 0.8972, end_f1 0.9159
2021-01-26 13:12:22 - train.py[line:106] - INFO: epoch 0, step 1150, loss 0.6283, start_f1 0.9400, end_f1 0.9505
2021-01-26 13:12:53 - train.py[line:106] - INFO: epoch 0, step 1200, loss 0.6507, start_f1 0.9623, end_f1 0.9533
2021-01-26 13:13:25 - train.py[line:106] - INFO: epoch 0, step 1250, loss 0.5009, start_f1 0.9739, end_f1 0.9655
2021-01-26 13:13:56 - train.py[line:106] - INFO: epoch 0, step 1300, loss 0.2936, start_f1 0.9796, end_f1 0.9796
2021-01-26 13:14:28 - train.py[line:106] - INFO: epoch 0, step 1350, loss 0.6308, start_f1 0.9391, end_f1 0.9412
2021-01-26 13:14:59 - train.py[line:106] - INFO: epoch 0, step 1400, loss 0.9615, start_f1 0.9573, end_f1 0.9661
2021-01-26 13:15:31 - train.py[line:106] - INFO: epoch 0, step 1450, loss 0.4069, start_f1 0.9910, end_f1 0.9730
2021-01-26 13:16:02 - train.py[line:106] - INFO: epoch 0, step 1500, loss 0.2833, start_f1 0.9800, end_f1 0.9800
2021-01-26 13:16:33 - train.py[line:106] - INFO: epoch 0, step 1550, loss 0.7665, start_f1 0.9449, end_f1 0.9524
2021-01-26 13:17:05 - train.py[line:106] - INFO: epoch 0, step 1600, loss 0.8316, start_f1 0.9365, end_f1 0.9457
2021-01-26 13:17:36 - train.py[line:106] - INFO: epoch 0, step 1650, loss 0.6758, start_f1 0.9322, end_f1 0.9667
2021-01-26 13:18:08 - train.py[line:106] - INFO: epoch 0, step 1700, loss 0.5496, start_f1 0.9358, end_f1 0.9464
2021-01-26 13:18:39 - train.py[line:106] - INFO: epoch 0, step 1750, loss 0.3558, start_f1 0.9580, end_f1 0.9744
2021-01-26 13:19:10 - train.py[line:106] - INFO: epoch 0, step 1800, loss 0.7836, start_f1 0.9744, end_f1 0.9744
2021-01-26 13:19:42 - train.py[line:106] - INFO: epoch 0, step 1850, loss 0.2154, start_f1 0.9818, end_f1 1.0000
2021-01-26 13:20:13 - train.py[line:106] - INFO: epoch 0, step 1900, loss 0.6944, start_f1 0.9825, end_f1 0.9825
2021-01-26 13:20:45 - train.py[line:106] - INFO: epoch 0, step 1950, loss 0.2413, start_f1 0.9608, end_f1 0.9804
2021-01-26 13:21:16 - train.py[line:106] - INFO: epoch 0, step 2000, loss 0.4267, start_f1 0.9412, end_f1 0.9524
2021-01-26 13:21:47 - train.py[line:106] - INFO: epoch 0, step 2050, loss 0.3233, start_f1 0.9505, end_f1 0.9703
2021-01-26 13:22:19 - train.py[line:106] - INFO: epoch 0, step 2100, loss 0.7402, start_f1 0.9550, end_f1 0.9725
2021-01-26 13:22:50 - train.py[line:106] - INFO: epoch 0, step 2150, loss 0.2253, start_f1 0.9899, end_f1 0.9899
2021-01-26 13:23:22 - train.py[line:106] - INFO: epoch 0, step 2200, loss 0.1404, start_f1 1.0000, end_f1 0.9735
2021-01-26 13:23:53 - train.py[line:106] - INFO: epoch 0, step 2250, loss 0.7533, start_f1 0.9524, end_f1 0.9434
2021-01-26 13:24:25 - train.py[line:106] - INFO: epoch 0, step 2300, loss 0.4177, start_f1 0.9541, end_f1 0.9811
2021-01-26 13:24:56 - train.py[line:106] - INFO: epoch 0, step 2350, loss 0.5558, start_f1 0.9346, end_f1 0.9174
2021-01-26 13:25:27 - train.py[line:106] - INFO: epoch 0, step 2400, loss 0.4829, start_f1 0.9434, end_f1 0.9720
2021-01-26 13:25:59 - train.py[line:106] - INFO: epoch 0, step 2450, loss 0.5004, start_f1 0.9474, end_f1 0.9636
2021-01-26 13:26:30 - train.py[line:106] - INFO: epoch 0, step 2500, loss 0.3895, start_f1 0.9709, end_f1 0.9709
2021-01-26 13:27:02 - train.py[line:106] - INFO: epoch 0, step 2550, loss 0.1246, start_f1 0.9907, end_f1 0.9907
2021-01-26 13:27:33 - train.py[line:106] - INFO: epoch 0, step 2600, loss 0.1828, start_f1 0.9910, end_f1 0.9818
2021-01-26 13:28:05 - train.py[line:106] - INFO: epoch 0, step 2650, loss 0.1095, start_f1 0.9919, end_f1 0.9919
2021-01-26 13:29:05 - train.py[line:136] - INFO: -----eval----
2021-01-26 13:29:05 - train.py[line:138] - INFO: epoch 0, step 2666, loss 0.7127, start_f1 0.9741, end_f1 0.9738
2021-01-26 13:29:05 - train.py[line:139] - INFO: -----eval----
2021-01-26 13:29:07 - train.py[line:143] - INFO: -----save the best model----
2021-01-26 13:29:28 - train.py[line:106] - INFO: epoch 1, step 2700, loss 0.4474, start_f1 0.9764, end_f1 0.9600
2021-01-26 13:30:00 - train.py[line:106] - INFO: epoch 1, step 2750, loss 0.1718, start_f1 0.9818, end_f1 0.9908
2021-01-26 13:30:31 - train.py[line:106] - INFO: epoch 1, step 2800, loss 0.8962, start_f1 0.9580, end_f1 0.9580
2021-01-26 13:31:03 - train.py[line:106] - INFO: epoch 1, step 2850, loss 0.3582, start_f1 0.9730, end_f1 0.9818
2021-01-26 13:31:34 - train.py[line:106] - INFO: epoch 1, step 2900, loss 0.6416, start_f1 0.9552, end_f1 0.9313
2021-01-26 13:32:06 - train.py[line:106] - INFO: epoch 1, step 2950, loss 0.2362, start_f1 0.9922, end_f1 0.9688
2021-01-26 13:32:37 - train.py[line:106] - INFO: epoch 1, step 3000, loss 0.2725, start_f1 0.9811, end_f1 0.9720
2021-01-26 13:33:08 - train.py[line:106] - INFO: epoch 1, step 3050, loss 0.3066, start_f1 0.9825, end_f1 0.9825
2021-01-26 13:33:40 - train.py[line:106] - INFO: epoch 1, step 3100, loss 0.2517, start_f1 0.9836, end_f1 0.9917
2021-01-26 13:34:11 - train.py[line:106] - INFO: epoch 1, step 3150, loss 0.8277, start_f1 0.9346, end_f1 0.9714
2021-01-26 13:34:43 - train.py[line:106] - INFO: epoch 1, step 3200, loss 0.1144, start_f1 0.9899, end_f1 0.9899
2021-01-26 13:35:14 - train.py[line:106] - INFO: epoch 1, step 3250, loss 0.0311, start_f1 1.0000, end_f1 1.0000
2021-01-26 13:35:46 - train.py[line:106] - INFO: epoch 1, step 3300, loss 0.2925, start_f1 0.9730, end_f1 0.9730
2021-01-26 13:36:17 - train.py[line:106] - INFO: epoch 1, step 3350, loss 0.0741, start_f1 0.9905, end_f1 1.0000
2021-01-26 13:36:49 - train.py[line:106] - INFO: epoch 1, step 3400, loss 0.2620, start_f1 0.9615, end_f1 1.0000
2021-01-26 13:37:20 - train.py[line:106] - INFO: epoch 1, step 3450, loss 0.1909, start_f1 0.9821, end_f1 1.0000
2021-01-26 13:37:51 - train.py[line:106] - INFO: epoch 1, step 3500, loss 0.5751, start_f1 0.9730, end_f1 0.9730
2021-01-26 13:38:23 - train.py[line:106] - INFO: epoch 1, step 3550, loss 0.8068, start_f1 0.9273, end_f1 0.9434
2021-01-26 13:38:54 - train.py[line:106] - INFO: epoch 1, step 3600, loss 0.1150, start_f1 0.9828, end_f1 0.9915
2021-01-26 13:39:26 - train.py[line:106] - INFO: epoch 1, step 3650, loss 0.2005, start_f1 0.9907, end_f1 0.9815
2021-01-26 13:39:57 - train.py[line:106] - INFO: epoch 1, step 3700, loss 0.1322, start_f1 1.0000, end_f1 0.9841
2021-01-26 13:40:29 - train.py[line:106] - INFO: epoch 1, step 3750, loss 0.3355, start_f1 0.9515, end_f1 0.9608
2021-01-26 13:41:00 - train.py[line:106] - INFO: epoch 1, step 3800, loss 0.0513, start_f1 1.0000, end_f1 1.0000
2021-01-26 13:41:32 - train.py[line:106] - INFO: epoch 1, step 3850, loss 0.0636, start_f1 1.0000, end_f1 0.9912
2021-01-26 13:42:03 - train.py[line:106] - INFO: epoch 1, step 3900, loss 0.0854, start_f1 0.9903, end_f1 1.0000
2021-01-26 13:42:35 - train.py[line:106] - INFO: epoch 1, step 3950, loss 0.0361, start_f1 1.0000, end_f1 1.0000
2021-01-26 13:43:06 - train.py[line:106] - INFO: epoch 1, step 4000, loss 1.6467, start_f1 0.9500, end_f1 0.9333
